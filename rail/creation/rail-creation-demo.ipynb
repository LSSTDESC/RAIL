{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `rail.creation` demo\n",
    "\n",
    "_Alex Malz (GCCL@RUB)_ & _Bryce Kalmbach (UW)_\n",
    "\n",
    "Stolen wholesale from [the XDGMM demo](https://github.com/tholoien/XDGMM/blob/master/Notebooks/Demo.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from xdgmm import XDGMM\n",
    "\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "from astroML.plotting.tools import draw_ellipse\n",
    "from astroML.plotting import setup_text_plots\n",
    "from sklearn.mixture import GaussianMixture as skl_GMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in simulated data\n",
    "\n",
    "Expensive to make but includes complex physical effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder\n",
    "\n",
    "N = 2000\n",
    "np.random.seed(0)\n",
    "\n",
    "# would have 6 instead of just x, y\n",
    "# generate the true data\n",
    "x_true = (1.4 + 2 * np.random.random(N)) ** 2\n",
    "y_true = 0.1 * x_true ** 2\n",
    "\n",
    "# add scatter to \"true\" distribution\n",
    "dx = 0.1 + 4. / x_true ** 2\n",
    "dy = 0.1 + 10. / x_true ** 2\n",
    "\n",
    "x_true += np.random.normal(0, dx, N)\n",
    "y_true += np.random.normal(0, dy, N)\n",
    "\n",
    "# add noise to get the \"observed\" distribution\n",
    "dx = 0.2 + 0.5 * np.random.random(N)\n",
    "dy = 0.2 + 0.5 * np.random.random(N)\n",
    "\n",
    "x = x_true + np.random.normal(0, dx)\n",
    "y = y_true + np.random.normal(0, dy)\n",
    "\n",
    "# stack the results for computation\n",
    "X = np.vstack([x, y]).T\n",
    "Xerr = np.zeros(X.shape + X.shape[-1:])\n",
    "diag = np.arange(X.shape[-1])\n",
    "Xerr[:, diag, diag] = np.vstack([dx ** 2, dy ** 2]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment simulated data\n",
    "\n",
    "To densely populate data space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model the augmented data\n",
    "\n",
    "To get a continuous model of data and truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune the interpolation model\n",
    "\n",
    "WARNING: SLOW!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an XDGMM model:\n",
    "xdgmm = XDGMM()\n",
    "\n",
    "# Define the range of component numbers, and get ready to compute the BIC for each one:\n",
    "param_range = np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "\n",
    "# Loop over component numbers, fitting XDGMM model and computing the BIC:\n",
    "bic, optimal_n_comp, lowest_bic = xdgmm.bic_test(X, Xerr, param_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bic(param_range,bics,lowest_comp):\n",
    "    plt.clf()\n",
    "    setup_text_plots(fontsize=16, usetex=True)\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    plt.bar(param_range-0.25,bics,color='blue',width=0.5)\n",
    "    plt.text(lowest_comp, bics.min() * 0.97 + .03 * bics.max(), '*',\n",
    "             fontsize=14, ha='center')\n",
    "\n",
    "    plt.xticks(param_range)\n",
    "    plt.ylim(bics.min() - 0.01 * (bics.max() - bics.min()),\n",
    "             bics.max() + 0.01 * (bics.max() - bics.min()))\n",
    "    plt.xlim(param_range.min() - 1, param_range.max() + 1)\n",
    "\n",
    "    plt.xticks(param_range,fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "\n",
    "\n",
    "    plt.xlabel('Number of components',fontsize=18)\n",
    "    plt.ylabel('BIC score',fontsize=18)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bic(param_range, bic, optimal_n_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_range = np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "shuffle_split = ShuffleSplit(3, test_size=0.3,random_state=0)\n",
    "\n",
    "train_scores,test_scores = validation_curve(xdgmm, X=X, y=Xerr, \n",
    "                                            param_name=\"n_components\",\n",
    "                                            param_range=param_range,\n",
    "                                            n_jobs=3,\n",
    "                                            cv=shuffle_split,\n",
    "                                            verbose=1)\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_val_curve(param_range, train_mean, train_std, test_mean,\n",
    "                   test_std):\n",
    "    plt.clf()\n",
    "    setup_text_plots(fontsize=16, usetex=True)\n",
    "    fig=plt.figure(figsize=(12,8))\n",
    "    plt.plot(param_range, train_mean, label=\"Training score\",\n",
    "             color=\"red\")\n",
    "    plt.fill_between(param_range, train_mean - train_std,\n",
    "                     train_mean + train_std, alpha=0.2, color=\"red\")\n",
    "    plt.plot(param_range, test_mean,label=\"Cross-validation score\",\n",
    "             color=\"green\")\n",
    "    plt.fill_between(param_range, test_mean - test_std,\n",
    "                     test_mean + test_std, alpha=0.2, color=\"green\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.xlabel(\"Number of Components\", fontsize=18)\n",
    "    plt.ylabel(\"Score\", fontsize=18)\n",
    "    plt.xlim(param_range.min(),param_range.max())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_val_curve(param_range, train_scores_mean, train_scores_std, test_scores_mean, test_scores_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate the augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdgmm.n_components = optimal_n_comp\n",
    "xdgmm = xdgmm.fit(X, Xerr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdgmm.save_model('demo_model.fit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduce systematics\n",
    "\n",
    "i.e. optionally degrade the model for realistic complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read model into an existing XDGMM object\n",
    "xdgmm.read_model('demo_model.fit')\n",
    "\n",
    "# Initialize a new XDGMM object using the model\n",
    "xdgmm2 = XDGMM(filename='demo_model.fit')\n",
    "\n",
    "# Comparison --- the arrays should be the same.\n",
    "print(xdgmm.weights)\n",
    "print(xdgmm2.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emulate data and truth\n",
    "\n",
    "Draw data and truth from continuous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = xdgmm.sample(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(x_true, y_true, x, y, sample, xdgmm):\n",
    "    setup_text_plots(fontsize=16, usetex=True)\n",
    "    plt.clf()\n",
    "    fig = plt.figure(figsize=(12, 9))\n",
    "    fig.subplots_adjust(left=0.1, right=0.95,\n",
    "                        bottom=0.1, top=0.95,\n",
    "                        wspace=0.02, hspace=0.02)\n",
    "\n",
    "    ax1 = fig.add_subplot(221)\n",
    "    ax1.scatter(x_true, y_true, s=4, lw=0, c='k')\n",
    "\n",
    "    ax2 = fig.add_subplot(222)\n",
    "\n",
    "    ax2.scatter(x, y, s=4, lw=0, c='k')\n",
    "\n",
    "    ax3 = fig.add_subplot(223)\n",
    "    ax3.scatter(sample[:, 0], sample[:, 1], s=4, lw=0, c='k')\n",
    "\n",
    "    ax4 = fig.add_subplot(224)\n",
    "    for i in range(xdgmm.n_components):\n",
    "        draw_ellipse(xdgmm.mu[i], xdgmm.V[i], scales=[2], ax=ax4,\n",
    "                     ec='k', fc='gray', alpha=0.2)\n",
    "\n",
    "    titles = [\"True Distribution\", \"Noisy Distribution\",\n",
    "              \"Extreme Deconvolution\\n  resampling\",\n",
    "            \"Extreme Deconvolution\\n  cluster locations\"]\n",
    "\n",
    "    ax = [ax1, ax2, ax3, ax4]\n",
    "\n",
    "    for i in range(4):\n",
    "        ax[i].set_xlim(-1, 13)\n",
    "        ax[i].set_ylim(-6, 16)\n",
    "\n",
    "        ax[i].xaxis.set_major_locator(plt.MultipleLocator(4))\n",
    "        ax[i].yaxis.set_major_locator(plt.MultipleLocator(5))\n",
    "\n",
    "        ax[i].text(0.05, 0.95, titles[i],\n",
    "                   ha='left', va='top', transform=ax[i].transAxes)\n",
    "\n",
    "        if i in (0, 1):\n",
    "            ax[i].xaxis.set_major_formatter(plt.NullFormatter())\n",
    "        else:\n",
    "            ax[i].set_xlabel('$x$', fontsize = 18)\n",
    "\n",
    "        if i in (1, 3):\n",
    "            ax[i].yaxis.set_major_formatter(plt.NullFormatter())\n",
    "        else:\n",
    "            ax[i].set_ylabel('$y$', fontsize = 18)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample(x_true, y_true, x, y, sample, xdgmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out photometry\n",
    "\n",
    "`ceci` HDF5 format for `rail.estimation` soon, CSV for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate true redshift posterior of sampled data\n",
    "\n",
    "Evaluate the continuous model at the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_X = np.array([np.nan, 1.5])\n",
    "cond_Xerr = np.array([0.0,0.05])\n",
    "cond_xdgmm = xdgmm.condition(X_input = cond_X,Xerr_input = cond_Xerr)\n",
    "\n",
    "# Compare the conditioned model to the original:\n",
    "print(xdgmm.weights)\n",
    "print(cond_xdgmm.weights)\n",
    "print(\"\\n\")\n",
    "print(xdgmm.mu)\n",
    "print(cond_xdgmm.mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cond_model(xdgmm, cond_xdgmm, y):\n",
    "    plt.clf()\n",
    "    setup_text_plots(fontsize=16, usetex=True)\n",
    "    fig = plt.figure(figsize=(12, 9))\n",
    "\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    for i in range(xdgmm.n_components):\n",
    "        draw_ellipse(xdgmm.mu[i], xdgmm.V[i], scales=[2], ax=ax1,\n",
    "                     ec='k', fc='gray', alpha=0.2)\n",
    "\n",
    "    ax1.plot([-2,15],[y,y],color='blue',linewidth=2)\n",
    "    ax1.set_xlim(-1, 13)\n",
    "    ax1.set_ylim(-6, 16)\n",
    "    ax1.set_xlabel('$x$', fontsize = 18)\n",
    "    ax1.set_ylabel('$y$', fontsize = 18)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    x = np.array([np.linspace(-2,14,1000)]).T\n",
    "\n",
    "    gmm=skl_GMM(n_components = cond_xdgmm.n_components,\n",
    "                covariance_type = 'full')\n",
    "    gmm.means_ = cond_xdgmm.mu\n",
    "    gmm.weights_ = cond_xdgmm.weights\n",
    "    gmm.covars_ = cond_xdgmm.V\n",
    "\n",
    "    logprob, responsibilities = gmm.score_samples(x)\n",
    "\n",
    "    pdf = np.exp(logprob)\n",
    "    ax2.plot(x, pdf, color='red', linewidth = 2,\n",
    "             label='Cond. dist. of $x$ given $y='+str(y)+'\\pm 0.05$')\n",
    "    ax2.legend()\n",
    "    ax2.set_ylabel('Probability', fontsize= 18 )\n",
    "    ax2.set_ylim(0, 0.52)\n",
    "    ax1.set_xlim(-1, 13)\n",
    "    plt.show()\n",
    "\n",
    "def plot_cond_sample(x, y):\n",
    "    plt.clf()\n",
    "    setup_text_plots(fontsize=16, usetex=True)\n",
    "    fig = plt.figure(figsize=(12, 9))\n",
    "\n",
    "    plt.hist(x, 50, histtype='step', color='red',lw=2)\n",
    "\n",
    "    plt.ylim(0,70)\n",
    "    plt.xlim(-1,13)\n",
    "\n",
    "    plt.xlabel('$x$', fontsize=18)\n",
    "    plt.ylabel('Number of Points', fontsize=18)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_conditional_predictions(y, true_x, predicted_x):\n",
    "    plt.clf()\n",
    "    setup_text_plots(fontsize=16, usetex=True)\n",
    "    fig = plt.figure(figsize=(12, 9))\n",
    "\n",
    "    plt.scatter(true_x, y, color='red', s=4, marker='o',\n",
    "                label=\"True Distribution\")\n",
    "    plt.scatter(predicted_x, y, color='blue', s=4, marker='o',\n",
    "                label=\"Predicted Distribution\")\n",
    "\n",
    "    plt.xlim(-1, 13)\n",
    "    plt.ylim(-6, 16)\n",
    "    plt.legend(loc=2, scatterpoints=1)\n",
    "\n",
    "    plt.xlabel('$x$', fontsize = 18)\n",
    "    plt.ylabel('$y$', fontsize = 18)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cond_model(xdgmm, cond_xdgmm, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_sample = cond_xdgmm.sample(1000)\n",
    "y = np.ones(1000)*1.5\n",
    "plot_cond_sample(cond_sample,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a dataset:\n",
    "true_sample = xdgmm.sample(1000)\n",
    "true_x = true_sample[:,0]\n",
    "y = true_sample[:,1]\n",
    "\n",
    "# Predict x values given y values:\n",
    "predicted_x = np.array([])\n",
    "for this_y in y:\n",
    "    # Specify y-conditioning to apply to P(x,y):\n",
    "    on_this = np.array([np.nan,this_y])\n",
    "    # Compute conditional PDF P(x|y):\n",
    "    cond_gmm = xdgmm.condition(on_this)\n",
    "    # Draw a sample x value from this PDF, and add it to the growing list\n",
    "    predicted_x = np.append(predicted_x, cond_gmm.sample())\n",
    "\n",
    "# Plot the two datasets, to compare the true x and the predicted x:\n",
    "plot_conditional_predictions(y, true_x, predicted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out true redshifts and posteriors\n",
    "\n",
    "Separate for blind estimation, must be compatible with `rail.evaluation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST-DESC (Python 3)",
   "language": "python",
   "name": "lsstdesc_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
