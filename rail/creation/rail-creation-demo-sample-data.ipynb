{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `rail.creation` demo: sampling (z, data) from a model of p(z, data)\n",
    "\n",
    "_Alex Malz (GCCL@RUB)_ & _Bryce Kalmbach (UW)_\n",
    "\n",
    "Stolen wholesale from [the XDGMM demo](https://github.com/tholoien/XDGMM/blob/master/Notebooks/Demo.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import corner\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "from astropy.io import fits\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import lines as mlines\n",
    "\n",
    "from xdgmm import XDGMM\n",
    "\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "from astroML.plotting.tools import draw_ellipse\n",
    "from astroML.plotting import setup_text_plots\n",
    "from sklearn.mixture import GaussianMixture as skl_GMM\n",
    "\n",
    "# from pam.ganNetwork import ganNetwork\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in simulated data\n",
    "\n",
    "Expensive to make but includes complex physical effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = h5py.File(os.path.join('../..',\n",
    "#                            'examples', 'testdata.hdf5'))\n",
    "# test_df = pd.DataFrame(np.array([f['photometry'][k][()] \\\n",
    "#                                 for k in f['photometry'].keys()]).T,\n",
    "#                        columns=f['photometry'].keys())\n",
    "# test_df = test_df.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment simulated data\n",
    "\n",
    "To densely populate data space\n",
    "\n",
    "Train GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# pz_gan = ganNetwork(seed=17)\n",
    "# n_epochs = 1500\n",
    "# pz_gan.train_gan(test_df.values, n_epochs, mini_batch_size=256, verbose=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model (if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #pz_gan = ganNetwork()\n",
    "# #pz_gan.load_model('rail_gan.model', 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate new catalog from GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_cat = pz_gan.create_gan_cat(500)\n",
    "# new_cat_df = pd.DataFrame(new_cat, columns=test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_cat_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure GAN looks like it is matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limits = [(21, 31)]*6\n",
    "# limits.insert(0, [-0.1, 3.1])\n",
    "# labels = ['redshift', 'u', 'g', 'r', 'i', 'z', 'y']\n",
    "# fig, axes = plt.subplots(7, 7, figsize=(14, 14))\n",
    "# corner.corner(new_cat_df[['redshift', 'mag_u_lsst', 'mag_g_lsst', 'mag_r_lsst', \n",
    "#                           'mag_i_lsst', 'mag_z_lsst', 'mag_y_lsst']], \n",
    "#               range=limits, labels=labels, fig=fig, label_kwargs={'size':20}, \n",
    "#               plot_datapoints=False, hist_kwargs={'density':True})\n",
    "# corner.corner(test_df[['redshift', 'mag_u_lsst', 'mag_g_lsst', 'mag_r_lsst', \n",
    "#                         'mag_i_lsst', 'mag_z_lsst', 'mag_y_lsst']],\n",
    "#               color='r', plot_datapoints=False, fig=fig, range=limits, labels=labels,\n",
    "#               hist_kwargs={'density':True})\n",
    "\n",
    "# black_line = mlines.Line2D([], [], color='k', label='GAN')\n",
    "# red_line = mlines.Line2D([], [], color='r', label='Original\\nData')\n",
    "\n",
    "# plt.legend(handles=[black_line,red_line],\n",
    "#             bbox_to_anchor=(0., 1.0, 1., .0), loc=4, fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pz_gan.save_model('rail_gan.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format data for `xdgmm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # stack the results for computation\n",
    "# X = np.vstack(new_cat_df[['redshift', 'mag_u_lsst', 'mag_g_lsst', 'mag_r_lsst', \n",
    "#                           'mag_i_lsst', 'mag_z_lsst', 'mag_y_lsst']].values)\n",
    "# Xerr = np.zeros(X.shape + X.shape[-1:])\n",
    "# diag = np.arange(X.shape[-1])\n",
    "# new_cat_df['errRedshift'] = 0.01\n",
    "# Xerr[:, diag, diag] = np.vstack(new_cat_df[['redshift', 'mag_u_lsst', 'mag_g_lsst', 'mag_r_lsst', \n",
    "#                           'mag_i_lsst', 'mag_z_lsst', 'mag_y_lsst']].values**2.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model the augmented data\n",
    "\n",
    "To get a continuous model of data and truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune the interpolation model\n",
    "\n",
    "WARNING: SLOW!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate an XDGMM model:\n",
    "# xdgmm = XDGMM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the range of component numbers, and get ready to compute the BIC for each one:\n",
    "# param_range = np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "\n",
    "# # Loop over component numbers, fitting XDGMM model and computing the BIC:\n",
    "# bic, optimal_n_comp, lowest_bic = xdgmm.bic_test(X, \n",
    "#                                                  Xerr,\n",
    "#                                                  param_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_bic(param_range,bics,lowest_comp):\n",
    "#     plt.clf()\n",
    "#     setup_text_plots(fontsize=16, usetex=True)\n",
    "#     fig = plt.figure(figsize=(12, 6))\n",
    "#     plt.bar(param_range-0.25,bics,color='blue',width=0.5)\n",
    "#     plt.text(lowest_comp, bics.min() * 0.97 + .03 * bics.max(), '*',\n",
    "#              fontsize=14, ha='center')\n",
    "\n",
    "#     plt.xticks(param_range)\n",
    "#     plt.ylim(bics.min() - 0.01 * (bics.max() - bics.min()),\n",
    "#              bics.max() + 0.01 * (bics.max() - bics.min()))\n",
    "#     plt.xlim(param_range.min() - 1, param_range.max() + 1)\n",
    "\n",
    "#     plt.xticks(param_range,fontsize=14)\n",
    "#     plt.yticks(fontsize=14)\n",
    "\n",
    "\n",
    "#     plt.xlabel('Number of components',fontsize=18)\n",
    "#     plt.ylabel('BIC score',fontsize=18)\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_bic(param_range, bic, optimal_n_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_range = np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "# shuffle_split = ShuffleSplit(3, test_size=0.3,random_state=0)\n",
    "\n",
    "# train_scores,test_scores = validation_curve(xdgmm, X=X, y=Xerr, \n",
    "#                                             param_name=\"n_components\",\n",
    "#                                             param_range=param_range,\n",
    "#                                             n_jobs=3,\n",
    "#                                             cv=shuffle_split,\n",
    "#                                             verbose=1)\n",
    "\n",
    "# train_scores_mean = np.mean(train_scores, axis=1)\n",
    "# train_scores_std = np.std(train_scores, axis=1)\n",
    "# test_scores_mean = np.mean(test_scores, axis=1)\n",
    "# test_scores_std = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_val_curve(param_range, train_mean, train_std, test_mean,\n",
    "#                    test_std):\n",
    "#     plt.clf()\n",
    "#     setup_text_plots(fontsize=16, usetex=True)\n",
    "#     fig=plt.figure(figsize=(12,8))\n",
    "#     plt.plot(param_range, train_mean, label=\"Training score\",\n",
    "#              color=\"red\")\n",
    "#     plt.fill_between(param_range, train_mean - train_std,\n",
    "#                      train_mean + train_std, alpha=0.2, color=\"red\")\n",
    "#     plt.plot(param_range, test_mean,label=\"Cross-validation score\",\n",
    "#              color=\"green\")\n",
    "#     plt.fill_between(param_range, test_mean - test_std,\n",
    "#                      test_mean + test_std, alpha=0.2, color=\"green\")\n",
    "\n",
    "#     plt.legend(loc=\"best\")\n",
    "#     plt.xlabel(\"Number of Components\", fontsize=18)\n",
    "#     plt.ylabel(\"Score\", fontsize=18)\n",
    "#     plt.xlim(param_range.min(),param_range.max())\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_val_curve(param_range, train_scores_mean, train_scores_std, test_scores_mean, test_scores_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate the augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an XDGMM model:\n",
    "xdgmm = XDGMM(n_components=2)\n",
    "#xdgmm.n_components = optimal_n_comp\n",
    "# xdgmm = xdgmm.fit(X, Xerr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xdgmm.save_model('demo_model.fit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduce systematics\n",
    "\n",
    "i.e. optionally degrade the model for realistic complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read model into an existing XDGMM object\n",
    "xdgmm.read_model('rail_xdgmm.fit')\n",
    "\n",
    "# # Initialize a new XDGMM object using the model\n",
    "# xdgmm2 = XDGMM(filename='rail_xdgmm.fit')\n",
    "\n",
    "# Comparison --- the arrays should be the same.\n",
    "print(xdgmm.weights)\n",
    "# print(xdgmm2.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emulate data and truth\n",
    "\n",
    "Draw data and truth from continuous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "sample = pd.DataFrame(xdgmm.sample(N), columns=['redshift', 'u', 'g', 'r', 'i', 'z', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner.corner(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_sample(x_true, y_true, x, y, sample, xdgmm):\n",
    "#     setup_text_plots(fontsize=16, usetex=True)\n",
    "#     plt.clf()\n",
    "#     fig = plt.figure(figsize=(12, 9))\n",
    "#     fig.subplots_adjust(left=0.1, right=0.95,\n",
    "#                         bottom=0.1, top=0.95,\n",
    "#                         wspace=0.02, hspace=0.02)\n",
    "\n",
    "#     ax1 = fig.add_subplot(221)\n",
    "#     ax1.scatter(x_true, y_true, s=4, lw=0, c='k')\n",
    "\n",
    "#     ax2 = fig.add_subplot(222)\n",
    "\n",
    "#     ax2.scatter(x, y, s=4, lw=0, c='k')\n",
    "\n",
    "#     ax3 = fig.add_subplot(223)\n",
    "#     ax3.scatter(sample[:, 0], sample[:, 1], s=4, lw=0, c='k')\n",
    "\n",
    "#     ax4 = fig.add_subplot(224)\n",
    "#     for i in range(xdgmm.n_components):\n",
    "#         draw_ellipse(xdgmm.mu[i, :2], xdgmm.V[i, :2, :2], scales=[2], ax=ax4,\n",
    "#                      ec='k', fc='gray', alpha=0.2)\n",
    "\n",
    "#     titles = [\"True Distribution\", \"Noisy Distribution\",\n",
    "#               \"Extreme Deconvolution\\n  resampling\",\n",
    "#             \"Extreme Deconvolution\\n  cluster locations\"]\n",
    "\n",
    "#     ax = [ax1, ax2, ax3, ax4]\n",
    "\n",
    "#     for i in range(4):\n",
    "\n",
    "#         ax[i].set_xlim(-1, 1)\n",
    "#         ax[i].set_ylim(20, 32)\n",
    "\n",
    "#         ax[i].xaxis.set_major_locator(plt.MultipleLocator(4))\n",
    "#         ax[i].yaxis.set_major_locator(plt.MultipleLocator(5))\n",
    "\n",
    "#         ax[i].text(0.05, 0.95, titles[i],\n",
    "#                    ha='left', va='top', transform=ax[i].transAxes)\n",
    "\n",
    "#         if i in (0, 1):\n",
    "#             ax[i].xaxis.set_major_formatter(plt.NullFormatter())\n",
    "#         else:\n",
    "#             ax[i].set_xlabel('$x$', fontsize = 18)\n",
    "\n",
    "#         if i in (1, 3):\n",
    "#             ax[i].yaxis.set_major_formatter(plt.NullFormatter())\n",
    "#         else:\n",
    "#             ax[i].set_ylabel('$y$', fontsize = 18)\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_true = test_df[['redshift']]\n",
    "# y_true = test_df[['mag_r_lsst']]\n",
    "# x = new_cat_df[['redshift']]\n",
    "# y = new_cat_df[['mag_r_lsst']]\n",
    "# plot_sample(x_true, y_true, x, y, sample, xdgmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out photometry\n",
    "\n",
    "`ceci` HDF5 format for `rail.estimation` soon, CSV for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate true redshift posterior of sampled data\n",
    "\n",
    "Evaluate the continuous model at the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_X = np.array([0.5, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "#cond_Xerr = np.array([0.0,0.05])\n",
    "cond_xdgmm = xdgmm.condition(X_input = cond_X)#,Xerr_input = cond_Xerr)\n",
    "\n",
    "# Compare the conditioned model to the original:\n",
    "print(xdgmm.weights)\n",
    "print(cond_xdgmm.weights)\n",
    "print(\"\\n\")\n",
    "print(xdgmm.mu)\n",
    "print(cond_xdgmm.mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cond_model(xdgmm, cond_xdgmm, y):\n",
    "    plt.clf()\n",
    "    setup_text_plots(fontsize=16, usetex=True)\n",
    "    fig = plt.figure(figsize=(12, 9))\n",
    "\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    for i in range(xdgmm.n_components):\n",
    "        draw_ellipse(xdgmm.mu[i], xdgmm.V[i], scales=[2], ax=ax1,\n",
    "                     ec='k', fc='gray', alpha=0.2)\n",
    "\n",
    "    ax1.plot([-2,15],[y,y],color='blue',linewidth=2)\n",
    "    ax1.set_xlim(-1, 13)\n",
    "    ax1.set_ylim(-6, 16)\n",
    "    ax1.set_xlabel('$x$', fontsize = 18)\n",
    "    ax1.set_ylabel('$y$', fontsize = 18)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    x = np.array([np.linspace(-2,14,1000)]).T\n",
    "\n",
    "    gmm=skl_GMM(n_components = cond_xdgmm.n_components,\n",
    "                covariance_type = 'full')\n",
    "    gmm.means_ = cond_xdgmm.mu\n",
    "    gmm.weights_ = cond_xdgmm.weights\n",
    "    gmm.covars_ = cond_xdgmm.V\n",
    "\n",
    "    logprob, responsibilities = gmm.score_samples(x)\n",
    "\n",
    "    pdf = np.exp(logprob)\n",
    "    ax2.plot(x, pdf, color='red', linewidth = 2,\n",
    "             label='Cond. dist. of $x$ given $y='+str(y)+'\\pm 0.05$')\n",
    "    ax2.legend()\n",
    "    ax2.set_ylabel('Probability', fontsize= 18 )\n",
    "    ax2.set_ylim(0, 0.52)\n",
    "    ax1.set_xlim(-1, 13)\n",
    "    plt.show()\n",
    "\n",
    "def plot_cond_sample(x, y):\n",
    "    plt.clf()\n",
    "    setup_text_plots(fontsize=16, usetex=True)\n",
    "    fig = plt.figure(figsize=(12, 9))\n",
    "\n",
    "    plt.hist(x, 50, histtype='step', color='red',lw=2)\n",
    "\n",
    "    plt.ylim(0,70)\n",
    "    #plt.xlim(-1,13)\n",
    "\n",
    "    plt.xlabel('$x$', fontsize=18)\n",
    "    plt.ylabel('Number of Points', fontsize=18)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_conditional_predictions(y, true_x, predicted_x):\n",
    "    plt.clf()\n",
    "    setup_text_plots(fontsize=16, usetex=True)\n",
    "    fig = plt.figure(figsize=(12, 9))\n",
    "\n",
    "    plt.scatter(true_x, y, color='red', s=4, marker='o',\n",
    "                label=\"True Distribution\")\n",
    "    plt.scatter(predicted_x, y, color='blue', s=4, marker='o',\n",
    "                label=\"Predicted Distribution\")\n",
    "\n",
    "    #plt.xlim(-1, 13)\n",
    "    #plt.ylim(-6, 16)\n",
    "    plt.legend(loc=2, scatterpoints=1)\n",
    "\n",
    "    plt.xlabel('$x$', fontsize = 18)\n",
    "    plt.ylabel('$y$', fontsize = 18)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cond_model(xdgmm, cond_xdgmm, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_sample = cond_xdgmm.sample(1000)\n",
    "y = np.ones(1000)*0.5\n",
    "plot_cond_sample(cond_sample[:,0],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a dataset:\n",
    "true_sample = xdgmm.sample(1000)\n",
    "true_x = true_sample[:,1]\n",
    "y = true_sample[:,0]\n",
    "\n",
    "# Predict x values given y values:\n",
    "predicted_x = np.array([])\n",
    "for this_y in y:\n",
    "    # Specify y-conditioning to apply to P(x,y):\n",
    "    on_this = np.array([this_y, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "    # Compute conditional PDF P(x|y):\n",
    "    cond_gmm = xdgmm.condition(on_this)\n",
    "    # Draw a sample x value from this PDF, and add it to the growing list\n",
    "    predicted_x = np.append(predicted_x, cond_gmm.sample()[:, 0])\n",
    "\n",
    "# Plot the two datasets, to compare the true x and the predicted x:\n",
    "plot_conditional_predictions(y, true_x, predicted_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out true redshifts and posteriors\n",
    "\n",
    "Separate for blind estimation, must be compatible with `rail.evaluation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST-DESC (Python 3)",
   "language": "python",
   "name": "lsstdesc_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
