{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: RAIL Evaluation \n",
    "\n",
    "_Sam Schmidt, Alex Malz, Julia Gschwend_ ([julia@linea.gov.br](mailto:julia@linea.gov.br))\n",
    "\n",
    "The purpose of this notebook is to demonstrate the use of the metrics scripts to be used on the photo-$z$ PDF catalogs produced by the PZ working group. The first implementation of the _evaluation_ module is based on the refactoring of the algorithms used in [Schmidt et al. 2020](https://arxiv.org/pdf/2001.03621.pdf), available on Github repository [PZDC1paper](https://github.com/LSSTDESC/PZDC1paper). \n",
    "\n",
    "To run this code, you must install qp and have the notebook in the same directory as metrics.py. You must also install some run-of-the-mill Python packages: matplotlib, numpy, scipy, and skgof.\n",
    "\n",
    "### Contents\n",
    "\n",
    "* [Sample](#sample)\n",
    " - [Run FZBoost](#fzboost)\n",
    " - [Old validation plots](#old_valid)  \n",
    "* [Metrics](#metrics)\n",
    " - [PIT and QQ plots](#pit_qq) \n",
    " - [CDE loss](#cde) \n",
    " - [KS](#ks) \n",
    " - [CvM](#cvm) \n",
    " - [AD](#ad) \n",
    "* [Summary](#summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Markdown\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sample import Sample\n",
    "from metrics import Metrics\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>WARNING: error when importing skgof -> No module named 'scipy._lib.six'.    </font>\n",
    "\n",
    "From [issue#4 of skgof repository](https://github.com/wrwrwr/scikit-gof/issues/4): \n",
    "    \n",
    "\"Simply importing skgof gives this error.\n",
    "\n",
    "Currently ecdfgof.py uses scipy._lib.six module which is not present in newer versions of scipy\n",
    "(probably because they don't support python 2 anymore).\n",
    "It should be updated to either use six directly or drop support for python 2 and use str instead of six.string_types.\" \n",
    "    \n",
    "\n",
    "\n",
    " <font color='red'>   Temporary solution: change source code of skgof to use six instead of scipy._lib.six.  </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"sample\"></a>\n",
    "\n",
    "# Sample  \n",
    "\n",
    "\n",
    "To compute the photo-z metrics of a given test sample, it is necessary to read the output of a photo-z code containing galaxies' photo-z PDFs. Let's use the toy data available in `tests/data/` (**test_dc2_training_9816.hdf5** and **test_dc2_validation_9816.hdf5**) and the configuration file available in `examples/configs/FZBoost.yaml` to generate a small samples of photo-z PDFs using the **FZBoost** algorithm available on RAIL's _estimation_ module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"fzboost\"></a>\n",
    "### Run FZBoost\n",
    "\n",
    "Go to dir  `<your_path>/RAIL/examples/` and run the command `python main.py configs/FZBoost.yaml`.\n",
    "The photo-z output files (inputs for this notebook) will be writen at: `<your_path>/RAIL/examples/results/FZBoost/test_FZBoost.hdf5`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>The new RAIL's version will produce output of the codes as qp files rather than the old format hdf5 files (Sam's message on Slack about RAIL's issue#33). TO DO: update the read() function of class Data </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = '/Users/julia/github/RAIL' # replace it by your path to RAIL's parent dir\n",
    "pdfs_file = my_path + '/examples/results/FZBoost/test_FZBoost.hdf5'\n",
    "valid_file = my_path + '/tests/data/test_dc2_validation_9816.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a Sample object containing both the PDFs and true redshifts for each photo-z code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = Sample(pdfs_file, valid_file, name=\"FZBoost - toy data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDFs of 5 galaxies for illustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gals = np.random.choice(len(ztrue), 5)\n",
    "gals = [540, 2256, 12175, 17802, 19502]\n",
    "colors = sample.plot_pdfs(gals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"old_valid\"></a>\n",
    "### Validation plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traditional validation plots (point colors follow the PDFs above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.plot_old_valid(gals=gals, colors=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"metrics\"></a>\n",
    "# Metrics\n",
    "\n",
    "The folowing metrics are computed based on the photo-z PDFs. Let's create a Metrics object to access the metrics and plots of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = Metrics(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"pit_qq\"></a>\n",
    "## Qualitative diagnostic plots\n",
    "\n",
    "## PIT\n",
    "\n",
    "The first metric we calculate is the Probability Integral Transform (PIT), which is the Cumulative Distribution Function (CDF) \n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathrm{CDF}(f, q)\\ =\\ \\int_{-\\infty}^{q}\\ f(z)\\ dz,\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "evaluated at the galaxy's true redshift for every galaxy $i$ in the catalog.\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathrm{PIT}(p_{i}(z);\\ z_{i})\\ =\\ \\int_{-\\infty}^{z^{true}_{i}}\\ p_{i}(z)\\ dz,\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "For instance, the PIT values for the 5 PDFs shown above are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.pit[gals]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PIT outlier rate\n",
    "\n",
    "The PIT outlier rate is a global metric defined as the fraction of galaxies in the sample with extreme PIT values (PIT $<10^{-4}$ or PIT $>0.9999$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"PIT outlier rate of this sample: {metrics.pit_out_rate:.4f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram of PIT values is a useful tool for a qualitative assessment of PDFs quality. It shows whether the PDFs are biased (tilted PIT histogram), under-dispersed (excess counts close to the boudaries 0 and 1), over-dispersed (lack of counts close the boudaries 0 and 1), or well-calibrated (flat histogram). By default, the `plot_pit()` function of the class Metrics considers 100 evenly spaced bins and shows the sample's name at the plot legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "metrics.plot_pit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The black horizontal line represents the ideal case where the PIT histogram would behave as a uniform distribution U(0,1). \n",
    "\n",
    "Let's explore different binning options. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "plt.figure(figsize=[12,3])\n",
    "metrics.plot_pit(bins=20, sp=131, label=\"20 bins\") # sp = subplot tag\n",
    "metrics.plot_pit(bins=60, sp=132, label=\"60 bins\")\n",
    "metrics.plot_pit(bins=np.linspace(0,1,80), sp=133, label=\"80 bins\")\n",
    "plt.subplots_adjust()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QQ plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quantile-quantile (QQ) plot can be used to compare qualitatively the PIT distribution obtained with the PDFs agaist the ideal case (uniform distribution). The closer the QQ plot is to the diagonal, the better is the PDFs calibration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "metrics.plot_qq()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot PIT histogram and QQ plots together, as done in DC1 paper. By default, the PIT binning follows the same number of quantiles attributed to the Metrics object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "metrics.plot_qq(show_pit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore a different number of quantiles. By default, a Metrics object is instantiated with parameter Nquants = 100 percentiles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_50 = Metrics(sample, Nquants=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "metrics_50.plot_qq(label=\"N$_{quants}$=50\", show_pit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> TO DO: IMPLEMENT QQ PLOT AS SUBPLOT. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=[16,3])\n",
    "#metrics_4.plot_qq(sp=141, label=\"N$_{quants}$=4, 4 bins\", show_pit=True)\n",
    "#metrics_25.plot_qq(sp=142, label=\"N$_{quants}$=25, 25 bins\", show_pit=True)\n",
    "#metrics.plot_qq(sp=143, label=\"N$_{quants}$=100, 100 bins\", show_pit=True)\n",
    "#metrics.plot_qq(sp=144, bins=25, label=\"N$_{quants}$=100, 25 bins\", show_pit=True)\n",
    "#plt.subplots_adjust()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"cde\"></a>\n",
    "## CDE Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>TO DO: change text\n",
    "    \n",
    " Next we can calculate the CDE loss described in Izbicki & Lee 2017 (arXiv:1704.08095)\n",
    "\n",
    "$$ \\int \\int ((p(z \\mid x) - \\hat{p}(z \\mid x))^{2} dz dP(x) $$\n",
    "\n",
    "which extends L2 density estimation loss to conditional density estimation.  We can estimate this quantity (up to an unknown additive constant which depends on the true conditional densities) from data as\n",
    "\n",
    "$$ \\frac{1}{n} \\sum_{i=1}^{n} \\int \\hat{p}^{2}(z \\mid x_{i}) dz - \\frac{2}{n} \\sum_{i=1}^{n} \\hat{p}(z_{i} \\mid x_{i}) $$\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"CDE loss of this sample: {metrics.cde_loss:.2f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"ks\"></a>\n",
    "## Kolmogorov-Smirnov  \n",
    "\n",
    "\n",
    "Next, we calculate the Kolmogorov-Smirnov (KS) test statistic,\n",
    "\\begin{equation*}\n",
    "\\mathrm{KS}(\\{p_{i}(z)\\}_{N};\\ \\{z_{i}\\}_{N})\\ =\\ \\max_{PIT}\\left[ \\left| CDF(\\{PIT(p_{i}(z);\\ z_{i})\\}_{N}) - CDF(\\{z_{i}\\}_{N}) \\right| \\right],\n",
    "\\end{equation*}\n",
    "on the distribution of PIT values, which should be uniform if the PDFs are perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_stat, ks_pval = metrics.KS()\n",
    "print(ks_stat)\n",
    "print(ks_pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"cvm\"></a>\n",
    "## Cramer-von Mises\n",
    "\n",
    "Similarly, we calculate the Cramer-von Mises (CvM) test statistic,\n",
    "\\begin{equation*}\n",
    "\\mathrm{CvM}(\\{p_{i}(z)\\}_{N};\\ \\{z_{i}\\}_{N})\\ =\\ \\int_{-\\infty}^{\\infty}\\ \\left(CDF(\\{PIT(p_{i}(z);\\ z_{i})\\}_{N})\\ -\\ CDF(\\{z_{i}\\}_{N})\\right)^{2}\\ \\mathrm{d}CDF(\\{z_{i}\\}_{N}),\n",
    "\\end{equation*}\n",
    "on the distribution of PIT values, which should be uniform if the PDFs are perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvm_stat,cvm_pval = metrics.CvM() \n",
    "print(cvm_stat)\n",
    "print(cvm_pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"ad\"></a>\n",
    "## Anderson-Darling \n",
    "\n",
    "And the Anderson-Darling (AD) test statistic,\n",
    "\\begin{equation*}\n",
    "\\mathrm{AD}(\\{p_{i}(z)\\}_{N};\\ \\{z_{i}\\}_{N})\\ =\\ \\int_{-\\infty}^{\\infty}\\frac{\\left(CDF(\\{PIT(p_{i}(z);\\ z_{i})\\}_{N})\\ -\\ CDF(\\{z_{i}\\}_{N})\\right)^{2}}{CDF(\\{z_{i}\\}_{N})\\ \\left(1\\ -\\ CDF(\\{z_{i}\\}_{N})\\right)}\\ \\mathrm{d}CDF(\\{z_{i}\\}_{N}),\n",
    "\\end{equation*}\n",
    "on the distribution of PIT values, which should be uniform if the PDFs are perfect.  However, for this test, we cut the ends of the distribution, which represent catastrophic utliers.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_stat,ad_pval = metrics.AD()\n",
    "print (ad_stat)\n",
    "print (ad_pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"summary\"></a>\n",
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics_table = metrics.all() \n",
    "md(metrics_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> TO DO: IMPLEMENT BOOTSTRAP ERRORS. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> TO DO: IMPLEMENT UNIT TESTS. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> QUESTION: METRICS AS FUNCTIONS OR SUBCLASSES? </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
